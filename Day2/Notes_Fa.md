مرور مفاهیم روز اول (Day 1 Recap)
1. یادگیری نظارت‌شده (Supervised Learning)
چیست؟
یادگیری بر اساس داده‌های برچسب‌دار که هدف (Target) مشخص دارند.
مثال: پیش‌بینی قیمت خانه بر اساس اندازه.

الگوریتم‌ها:

رگرسیون خطی (Linear Regression)
طبقه‌بندی (Classification): مانند Logistic Regression.

مرور مفاهیم روز اول (Day 1 Recap)
1. یادگیری نظارت‌شده (Supervised Learning)
چیست؟
یادگیری بر اساس داده‌های برچسب‌دار که هدف (Target) مشخص دارند.
مثال: پیش‌بینی قیمت خانه بر اساس اندازه.

الگوریتم‌ها:

رگرسیون خطی (Linear Regression)
طبقه‌بندی (Classification): مانند Logistic Regression.

3. پیش‌پردازش داده‌ها (Data Preprocessing)
مراحل:
مدیریت داده‌های گمشده.
مقیاس‌بندی داده‌ها (Scaling).
رمزگذاری متغیرهای متنی.
تقسیم داده‌ها به آموزشی و آزمایشی.

4. انتخاب ویژگی‌ها (Feature Selection)
بررسی اهمیت ویژگی‌ها با درخت تصمیم.
استفاده از Correlation برای حذف ویژگی‌های تکراری.

کد ارائه‌شده از کتابخانه‌های scikit-learn برای انجام یک مدل رگرسیون لجستیک استفاده می‌کند. در زیر هر بخش از کد به تفصیل توضیح داده شده است:

وارد کردن کتابخانه‌ها:

python
Copy code
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
LogisticRegression: این کلاس برای ایجاد و آموزش مدل رگرسیون لجستیک استفاده می‌شود.
train_test_split: این تابع برای تقسیم داده‌ها به مجموعه‌های آموزشی و تست استفاده می‌شود.
تعریف داده‌های نمونه:

python
Copy code
X = [[25], [30], [35], [40]]  # سن
y = [0, 0, 1, 1]  # برچسب (0: بیماری ندارد، 1: بیماری دارد)
X: یک لیست از لیست‌ها که هر زیرلیست شامل یک ویژگی (در اینجا سن) برای هر نمونه است.
y: لیست برچسب‌ها که نشان می‌دهد آیا هر نمونه بیماری دارد یا خیر.
تقسیم داده‌ها به مجموعه‌های آموزشی و تست:

python
Copy code
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
test_size=0.25: 25٪ از داده‌ها برای تست و 75٪ برای آموزش مدل استفاده می‌شود.
random_state=42: برای اطمینان از قابل تکرار بودن تقسیم داده‌ها.
آموزش مدل رگرسیون لجستیک:

python
Copy code
model = LogisticRegression()
model.fit(X_train, y_train)
ایجاد یک شیء از مدل رگرسیون لجستیک.
آموزش مدل با استفاده از داده‌های آموزشی (X_train و y_train).
پیش‌بینی با مدل آموزش‌دیده:

python
Copy code
predictions = model.predict(X_test)
print("Predictions:", predictions)
استفاده از مدل آموزش‌دیده برای پیش‌بینی برچسب‌های مجموعه تست.
چاپ نتایج پیش‌بینی شده.
توضیحات اضافی:

رگرسیون لجستیک یک الگوریتم طبقه‌بندی باینری است که احتمال تعلق یک نمونه به یک کلاس خاص را پیش‌بینی می‌کند.
تقسیم داده‌ها به مجموعه‌های آموزشی و تست به منظور ارزیابی عملکرد مدل روی داده‌های نادیده‌ شده است.
پارامتر random_state برای اطمینان از اینکه تقسیم داده‌ها در هر اجرا یکسان باشد، استفاده می‌شود.
کاربرد رگرسیون لجستیک
رگرسیون لجستیک یکی از الگوریتم‌های پرکاربرد در یادگیری ماشین و آمار برای مسائل طبقه‌بندی باینری (دو‌کلاسه) است. در ادامه به برخی از کاربردهای اصلی این الگوریتم اشاره می‌کنیم:

پزشکی و تشخیص بیماری‌ها:

مثال کد شما: در کد ارائه‌شده، رگرسیون لجستیک برای پیش‌بینی وجود یا عدم وجود بیماری بر اساس سن افراد استفاده شده است. این مدل می‌تواند با استفاده از ویژگی‌های بیشتری مانند فشار خون، میزان کلسترول و سایر عوامل خطر، دقت پیش‌بینی را افزایش دهد.
کاربردهای دیگر: تشخیص سرطان، دیابت، بیماری‌های قلبی و سایر بیماری‌های مزمن.
بازاریابی و فروش:

پیش‌بینی این که آیا یک مشتری خاص احتمال دارد که خریدی انجام دهد یا خیر.
شناسایی مشتریانی که ممکن است از خدمات یا محصولات راضی نباشند و نیاز به اقدامات بازاریابی خاص دارند.
مالی و اعتبارسنجی:

ارزیابی احتمال عدم بازپرداخت وام توسط مشتریان.
شناسایی تقلب‌های مالی در تراکنش‌های بانکی.
امنیت و تشخیص نفوذ:

تشخیص نفوذ در سیستم‌های کامپیوتری با شناسایی رفتارهای غیرعادی.
شناسایی ویروس‌ها و بدافزارها بر اساس الگوهای رفتاری.
تحلیل اجتماعی و علوم انسانی:

پیش‌بینی نتایج انتخابات بر اساس نظرسنجی‌ها و داده‌های جمعیتی.
تحلیل احساسات در شبکه‌های اجتماعی برای شناسایی نظرات مثبت یا منفی کاربران نسبت به یک موضوع خاص.
مهندسی و تولید:

پیش‌بینی خرابی ماشین‌آلات بر اساس داده‌های حسگرها.
کنترل کیفیت تولید با شناسایی محصولات معیوب قبل از ارسال به بازار.
تجزیه و تحلیل متون و زبان طبیعی:

طبقه‌بندی ایمیل‌ها به عنوان اسپم یا غیر اسپم.
تحلیل احساسات متون برای تعیین مثبت یا منفی بودن نظرات کاربران.
چرا رگرسیون لجستیک؟
سادگی و کارایی: الگوریتمی ساده و سریع که برای داده‌های با ابعاد کم تا متوسط مناسب است.
قابلیت تفسیر: وزن‌های مدل قابل تفسیر هستند و می‌توانند نشان دهند که هر ویژگی چقدر بر پیش‌بینی نهایی تأثیر دارد.
احتمال‌بخش بودن: خروجی مدل می‌تواند به صورت احتمال تفسیر شود که اطلاعات بیشتری نسبت به طبقه‌بندی قطعی ارائه می‌دهد.
ثبات و عملکرد خوب: در بسیاری از موارد، رگرسیون لجستیک عملکرد خوبی در مقایسه با مدل‌های پیچیده‌تر دارد، به‌ویژه زمانی که داده‌ها خطی باشند یا به خوبی قابل تفکیک باشند.
نتیجه‌گیری
رگرسیون لجستیک یک ابزار قدرتمند و پرکاربرد در تحلیل داده‌ها و پیش‌بینی نتایج باینری است. با استفاده از این الگوریتم، می‌توان تصمیمات آگاهانه‌تری در حوزه‌های مختلف اتخاذ کرد و الگوهای مهم در داده‌ها را شناسایی نمود. برای بهبود عملکرد مدل، می‌توان از ویژگی‌های بیشتر، تکنیک‌های پیش‌پردازش داده و تنظیمات بهینه‌سازی استفاده کرد.
2. K-Means Clustering
فارسی:
الگوریتم K-Means یک روش برای خوشه‌بندی داده‌ها است. داده‌ها به 
𝑘
k خوشه تقسیم می‌شوند که نقاط درون هر خوشه به مرکز آن نزدیک‌تر هستند.


کاربردها | Applications:
گروه‌بندی مشتریان.
شناسایی الگوهای تصاویر.
تحلیل داده‌های ژنتیکی.
مثال عملی با توضیحات بیشتر
فرض کنید داده‌های شما شامل دو ویژگی (مثلاً سن و وزن) برای چند نفر است:

python
Copy code
data = np.array([
    [25, 80],  # فرد اول: سن 25، وزن 80
    [30, 60],  # فرد دوم: سن 30، وزن 60
    [35, 85],  # فرد سوم: سن 35، وزن 85
    [40, 40],  # فرد چهارم: سن 40، وزن 40
    [50, 20]   # فرد پنجم: سن 50، وزن 20
])
ایجاد مدل:

python
Copy code
kmeans = KMeans(n_clusters=2, random_state=42)
ما می‌خواهیم این افراد را به دو گروه تقسیم کنیم.

آموزش مدل:

python
Copy code
kmeans.fit(data)
الگوریتم K-Means مراکز خوشه‌ها را پیدا می‌کند و هر فرد را به نزدیک‌ترین خوشه اختصاص می‌دهد.

نمایش نتایج:

python
Copy code
print("Cluster Labels:", kmeans.labels_)
print("Centroids:", kmeans.cluster_centers_)
فرض کنید خروجی به این شکل باشد:

plaintext
Copy code
Cluster Labels: [1 1 1 0 0]
Centroids: [[45. 30.]
            [30. 75.]]
Cluster Labels: نشان می‌دهد که فرد اول، دوم و سوم به خوشه 1 تعلق دارند و فرد چهارم و پنجم به خوشه 0 تعلق دارند.
Centroids: مراکز خوشه‌ها:
خوشه 0: مرکز در سن 45 و وزن 30.
خوشه 1: مرکز در سن 30 و وزن 75.
نتیجه‌گیری
الگوریتم K-Means یک ابزار ساده اما قدرتمند برای گروه‌بندی داده‌ها است. با تعیین تعداد خوشه‌ها و آموزش مدل روی داده‌های خود، می‌توانید الگوهای پنهان در داده‌ها را شناسایی کنید. پارامتر random_state به شما کمک می‌کند تا نتایج قابل تکراری داشته باشید، و با انتخاب تعداد خوشه‌های مناسب (n_clusters)، می‌توانید بهترین تقسیم‌بندی را برای داده‌های خود پیدا کنید.
آیا استانداردی برای n_clusters=2 وجود دارد؟

خیر، هیچ استاندارد کلی برای انتخاب تعداد خوشه‌ها (n_clusters) وجود ندارد. مقدار بهینه برای این پارامتر بستگی به داده‌های شما و هدف تحلیل دارد. انتخاب تعداد خوشه‌ها باید با درک عمیق از داده‌ها و نیازهای مسئله انجام شود.
چگونه مقدار مناسب برای n_clusters را انتخاب کنیم؟

برای تعیین تعداد بهینه خوشه‌ها، می‌توانید از روش‌های زیر استفاده کنید:

روش آرنج (Elbow Method):

این روش شامل رسم نمودار مقدار خطای داخلی (Within-Cluster Sum of Squares - WCSS) در مقابل تعداد خوشه‌ها است.
با افزایش تعداد خوشه‌ها، WCSS کاهش می‌یابد. نقطه‌ای که کاهش WCSS به طور ناگهانی کند می‌شود، معمولاً تعداد خوشه‌های بهینه را نشان می‌دهد.
ضریب سیلوئت (Silhouette Score):

این معیار میزان مشابهت یک نقطه با خوشه خودش را نسبت به خوشه‌های دیگر اندازه‌گیری می‌کند.
مقادیر نزدیک به +1 نشان‌دهنده خوشه‌بندی خوب هستند، در حالی که مقادیر نزدیک به 0 نشان‌دهنده هم‌پوشانی خوشه‌ها هستند.
مثال:
python
Copy code
from sklearn.metrics import silhouette_score

silhouette_scores = []
for i in range(2, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    cluster_labels = kmeans.fit_predict(data)
    score = silhouette_score(data, cluster_labels)
    silhouette_scores.append(score)

plt.plot(range(2, 11), silhouette_scores, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Method')
plt.show()
دانش قبلی و هدف تحلیل:

گاهی اوقات بر اساس دانش قبلی از داده‌ها یا نیازهای خاص پروژه، تعداد خوشه‌ها تعیین می‌شود.
به عنوان مثال، اگر می‌دانید که داده‌ها به دو گروه اصلی تقسیم می‌شوند، می‌توانید n_clusters=2 را انتخاب کنید.
روش‌های دیگر:

روش گرافیکی Dendrogram برای خوشه‌بندی سلسله‌مراتبی.
روش Gap Statistic که فاصله بین خوشه‌ها را نسبت به توزیع مرجع اندازه‌گیری می‌کند.
2. انتخاب مقدار random_state
آیا استانداردی برای random_state=42 وجود دارد؟

پارامتر random_state برای تنظیم بذر (seed) تولید اعداد تصادفی استفاده می‌شود تا نتایج قابل تکرار باشند. عدد 42 به عنوان یک انتخاب معمول و شناخته‌شده به خاطر فرهنگ عامه (مثلاً از کتاب "The Hitchhiker's Guide to the Galaxy") استفاده می‌شود، اما هیچ استاندارد خاصی برای آن وجود ندارد. می‌توانید هر عدد صحیح دیگری نیز استفاده کنید.

چگونه مقدار مناسب برای random_state را انتخاب کنیم؟

برای تکرارپذیری: اگر می‌خواهید نتایج خوشه‌بندی‌تان قابل تکرار باشد (مثلاً برای گزارش‌ها یا تحقیقات علمی)، باید مقدار random_state را ثابت نگه دارید. می‌توانید هر عدد صحیح مثلاً 0، 1، 42، و غیره انتخاب کنید.

مثال:

python
Copy code
kmeans = KMeans(n_clusters=3, random_state=0)
برای آزمون‌های مختلف: اگر می‌خواهید چندین بار الگوریتم را با تنظیمات مختلف آزمایش کنید، می‌توانید مقادیر مختلف random_state را امتحان کنید تا ببینید چگونه بر نتایج تأثیر می‌گذارد.

اگر اهمیتی ندارد: اگر تکرارپذیری برای شما مهم نیست و فقط می‌خواهید خوشه‌بندی را اجرا کنید، می‌توانید random_state را تنظیم نکنید. اما توجه داشته باشید که نتایج هر بار ممکن است متفاوت باشند.
42 به‌صورت رایج استفاده می‌شود (بخاطر شوخی‌ای که از کتاب "The Hitchhiker's Guide to the Galaxy" نشأت گرفته است).
3. Overfitting و Underfitting

Overfitting: مدل بیش از حد به داده‌های آموزشی وابسته است و روی داده‌های جدید عملکرد خوبی ندارد.
Underfitting: مدل نتوانسته الگوهای داده‌های آموزشی را به درستی یاد بگیرد.
نمودار:

Underfitting: خط ساده‌ای که الگوها را یاد نگرفته است.
Overfitting: منحنی پیچیده‌ای که فقط داده‌های آموزشی را دنبال می‌کند.
Good Fit: خط یا منحنی‌ای که تعادل دارد.
4. ارزیابی مدل (Model Evaluation)

Cross-Validation: تقسیم داده‌ها به چندین بخش برای ارزیابی بهتر مدل.
Metrics: معیارهایی مثل Accuracy، Precision، و Recall برای ارزیابی عملکرد.
1. Cross-Validation (اعتبارسنجی متقاطع)
تعریف: اعتبارسنجی متقاطع روشی برای ارزیابی عملکرد مدل است که داده‌ها را به چندین بخش یا "فولد" (fold) تقسیم می‌کند. مدل به صورت چرخشی روی یک بخش تست و روی بقیه بخش‌ها آموزش داده می‌شود.
هدف: کاهش تأثیر بایاس (bias) و واریانس (variance) و ارائه ارزیابی قابل اعتمادتر از مدل.
روش‌های رایج:
k-Fold Cross-Validation: داده‌ها به k قسمت تقسیم می‌شوند. در هر مرحله، یک قسمت برای تست و باقی قسمت‌ها برای آموزش استفاده می‌شود.
Stratified k-Fold: مشابه k-Fold، اما توزیع کلاس‌ها در هر فولد حفظ می‌شود (مخصوص مسائل طبقه‌بندی).
Leave-One-Out Cross-Validation (LOOCV): هر بار فقط یک داده به عنوان تست استفاده می‌شود و بقیه داده‌ها برای آموزش.
2. Metrics (معیارهای ارزیابی مدل)
فارسی:
Accuracy (دقت):

تعریف: نسبت پیش‌بینی‌های صحیح به کل پیش‌بینی‌ها.
مثال: اگر 100 نمونه داشته باشیم و مدل 90 پیش‌بینی صحیح انجام دهد، دقت برابر است با 

محدودیت: در داده‌های نامتوازن، دقت ممکن است گمراه‌کننده باشد.
Precision (دقت مثبت):

تعریف: نسبت پیش‌بینی‌های مثبت صحیح به کل پیش‌بینی‌های مثبت.

 
کاربرد: زمانی که هزینه‌ی خطای مثبت کاذب (FP) زیاد است.
Recall (بازخوانی):

تعریف: نسبت پیش‌بینی‌های مثبت صحیح به کل داده‌های مثبت واقعی.

​
 
کاربرد: زمانی که شناسایی همه موارد مثبت اهمیت دارد (مثلاً در تشخیص سرطان).
F1-Score (امتیاز F1):

تعریف: میانگین هماهنگ Precision و Recall.
​
 
کاربرد: زمانی که تعادل بین Precision و Recall مهم است.

STDOUT/STDERR
Cross-Validation Accuracy (Mean): 0.8799999999999999
Accuracy: 0.87
Precision: 0.8333333333333334
Recall: 0.9042553191489362
F1-Score: 0.8673469387755102
خروجی مثال:
Cross-Validation Accuracy (Mean): 0.88

دقت متوسط مدل روی داده‌های آموزشی در طول 5 فولد اعتبارسنجی متقاطع.
Accuracy: 0.87

مدل روی داده‌های تست 87٪ پیش‌بینی صحیح انجام داده است.
Precision: 0.83

از تمام پیش‌بینی‌های مثبت مدل، 83٪ درست بوده است.
Recall: 0.90

مدل توانسته 90٪ از موارد مثبت واقعی را به درستی شناسایی کند.
F1-Score: 0.87

میانگین هماهنگ Precision و Recall، نشان‌دهنده تعادل عملکرد مدل است.
کاربرد:
این معیارها به شما کمک می‌کنند تصمیم بگیرید که آیا مدل شما برای استفاده واقعی آماده است یا نیاز به بهبود دارد. مثلاً:

اگر Precision پایین باشد، مدل موارد مثبت اشتباه زیادی دارد (مهم در مسائل مالی یا امنیتی).
اگر Recall پایین باشد، مدل بسیاری از موارد مثبت واقعی را از دست می‌دهد (مهم در مسائل پزشکی).